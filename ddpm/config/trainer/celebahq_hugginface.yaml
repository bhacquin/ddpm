defaults:
  - base_trainer
name: celeba_diffusion
platform: local
single_gpu: false
type: hugginface

# train: True #train from scratch
# eval: False #load ckpt.pt and evaluate FID and IS
test_session: False
qualitative_experiment: True
# Model ID hugginface
model_id: google/ddpm-ema-celebahq-256
log_root: /home/bastienvandelft/results #/mnt/scitas/bastien
random_seed: true

# Dataset
datapath: /home/bastienvandelft/Datasets/CelebAMask-HQ/CelebA-HQ-img #/mnt/scitas/bastien/CelebAMask-HQ/CelebA-HQ-img #help='dataset path if downloaded
dataset: CELEBAHQ #help='dataset name')
exp_name_folder: tests_corruptions
lsun_category: # one of ["bedroom","bridge","church_outdoor","classroom","conference_room","dining_room","kitchen","living_room","restaurant","tower",
corruptions_list: ['fog', 'contrast'] #['gaussian_blur',"frost","speckle_noise","snow","motion_blur","pixelate","glass_blur",
                  #"elastic_transform",'impulse_noise', "shot_noise", "gaussian_noise",'masking_vline_random_color','masking_random_color'] 
                  #["frost", "speckle_noise",'impulse_noise', "shot_noise", "gaussian_noise","jpeg_compression","pixelate",
                  #"fog","gaussian_blur","elastic_transform", "motion_blur","glass_blur","brightness", "saturate",
                  #'snow', 'masking_vline_random_color', 'spatter', 'contrast', 'masking_random_color']
new_corruptions_list: ['cocentric_sine_waves']
split: all
use_val: false
num_workers: 4 #help='workers of Dataloader')
corruption:  #help=corruption type base on Imagenet-C
corruption_severity:  #help='corruption severity level 1-5'
random_flip: False #help='Whether to use random flip in training')
# lower_image_size: 
# original_img_size: []
img_size: 256 #help='image size')

# Inference
run_sdedit: false
run_all_epsilon: true
use_std_schedule: false
number_of_image: 1000
number_of_sample: 1
image_number: 
batch_size: 1 #help='batch size'
annealing: 10
annealing_cst: 0.75
normalize: false 
normalize_mean: false
clip_inputs: false
number_of_stds: 3
min_epsilon: 1e-6
max_epsilon: 2e-4
number_of_epsilons: 6
dynamic_thresholding_langevin: false
dynamic_thresholding_ddim: true
dynamic_threshol_ratio: 0.99
dynamic_threshold_max: 1.3
number_of_latents_corrected: 2
min_latent_space_update: 99
clip_input_encoding: true
clip_input_decoding: false
clip_inputs_langevin: false
stop_clipping_at: 0
start_from_latent: True
ode_range: [199, 200, 1]
sde_range: [199,400,100]
number_of_timesteps: 200
# Logging & Sampling
number_of_steps: [200]
logdir: ${trainer.log_root}/logs/CelebaHQ #help='log directory')
base_dir: /home/bastienvandelft/Projects/ddpm
wandb_entity: bastienvd #help='wandb id to use')
ml_exp_name: ${trainer.dataset}_${trainer.lsun_category}_folder_${trainer.exp_name_folder} #help = 'name of the experience on wandb')


